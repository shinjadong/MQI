#!/usr/bin/env python3
"""
CCTV Google Sheets to Supabase ìë™ ë™ê¸°í™” ì‹œìŠ¤í…œ
30ë¶„ë§ˆë‹¤ Google Sheetsë¥¼ ë‹¤ìš´ë¡œë“œí•˜ì—¬ Claude AIê°€ ë¶„ë¥˜í•œ ê²°ê³¼ë¥¼ customer_inquiries í…Œì´ë¸”ì— ì €ì¥
"""

import os
import sys
import json
import logging
import pandas as pd
import schedule
import time
from datetime import datetime, timezone
from typing import Dict, List, Optional, Any, Union
from dotenv import load_dotenv
from supabase import create_client, Client
from google_sheets_manager_improved import GoogleSheetsManagerImproved
import anthropic
import asyncio
import re

# í™˜ê²½ ë³€ìˆ˜ ë¡œë“œ
load_dotenv()

# ë¡œê¹… ì„¤ì •
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(levelname)s - %(message)s',
    handlers=[
        logging.FileHandler('cctv_sync.log'),
        logging.StreamHandler()
    ]
)
logger = logging.getLogger(__name__)

class AIDataClassifier:
    """Claude AIë¥¼ í™œìš©í•œ ë°ì´í„° ë¶„ë¥˜ ì‹œìŠ¤í…œ"""
    
    def __init__(self, api_key: str):
        self.client = anthropic.Anthropic(api_key=api_key)
        self.timeout = int(os.getenv('AI_CLASSIFICATION_TIMEOUT', '30'))
        
    def classify_data(self, sheet_name: str, data_sample: List[Dict]) -> Dict[str, Any]:
        """
        Google Sheets ë°ì´í„°ë¥¼ Claude AIê°€ ë¶„ì„í•˜ì—¬ ë¶„ë¥˜
        
        Args:
            sheet_name: ì‹œíŠ¸ ì´ë¦„
            data_sample: ë¶„ì„í•  ë°ì´í„° ìƒ˜í”Œ (ìµœëŒ€ 5ê°œ)
            
        Returns:
            ë¶„ë¥˜ ê²°ê³¼ ë”•ì…”ë„ˆë¦¬
        """
        try:
            # ìƒ˜í”Œ ë°ì´í„° ì¤€ë¹„ (ìµœëŒ€ 5ê°œ ë ˆì½”ë“œ)
            sample_data = data_sample[:5] if len(data_sample) > 5 else data_sample
            
            # ë¶„ë¥˜ í”„ë¡¬í”„íŠ¸ ìƒì„±
            prompt = self._create_classification_prompt(sheet_name, sample_data)
            
            # Claude API í˜¸ì¶œ
            response = self.client.messages.create(
                model="claude-3-5-sonnet-20241022",
                max_tokens=1000,
                temperature=0.1,
                messages=[
                    {"role": "user", "content": prompt}
                ]
            )
            
            # ì‘ë‹µ íŒŒì‹± - í…ìŠ¤íŠ¸ ë¸”ë¡ë§Œ ì¶”ì¶œ
            response_text = ""
            for content_block in response.content:
                if content_block.type == "text":
                    response_text += content_block.text
            
            return self._parse_classification_response(response_text)
            
        except Exception as e:
            logger.error(f"AI ë¶„ë¥˜ ì‹¤íŒ¨: {e}")
            return self._get_fallback_classification(sheet_name)
    
    def _create_classification_prompt(self, sheet_name: str, data_sample: List[Dict]) -> str:
        """ë¶„ë¥˜ë¥¼ ìœ„í•œ í”„ë¡¬í”„íŠ¸ ìƒì„±"""
        
        # ë°ì´í„° ìƒ˜í”Œì„ ì½ê¸° ì‰¬ìš´ í˜•íƒœë¡œ ë³€í™˜
        sample_text = ""
        for i, record in enumerate(data_sample, 1):
            sample_text += f"ìƒ˜í”Œ {i}:\n"
            for key, value in record.items():
                if pd.notna(value) and str(value).strip():
                    sample_text += f"  {key}: {value}\n"
            sample_text += "\n"
        
        prompt = f"""
ë‹¤ìŒì€ Google Sheetsì—ì„œ ê°€ì ¸ì˜¨ ê³ ê° ë°ì´í„°ì…ë‹ˆë‹¤. ì´ ë°ì´í„°ë¥¼ ë¶„ì„í•˜ì—¬ ì–´ë–¤ ìœ í˜•ì˜ ë¬¸ì˜ì¸ì§€ ë¶„ë¥˜í•´ì£¼ì„¸ìš”.

**ì‹œíŠ¸ ì´ë¦„**: {sheet_name}

**ë°ì´í„° ìƒ˜í”Œ**:
{sample_text}

**ë¶„ë¥˜ ê¸°ì¤€**:
1. **estimate**: ê²¬ì  ë¬¸ì˜ (CCTV ì„¤ì¹˜ ê²¬ì , ì¹´ë©”ë¼ ê°œìˆ˜, ì˜ˆì‚° ê´€ë ¨)
2. **consultation**: ìƒë‹´ ì‹ ì²­ (ì „í™” ìƒë‹´, ë°©ë¬¸ ìƒë‹´ ìš”ì²­)
3. **inquiry**: ì¼ë°˜ ë¬¸ì˜ (ê¸°íƒ€ ì§ˆë¬¸, ì œí’ˆ ë¬¸ì˜)
4. **cctv_management**: CCTV ê´€ë¦¬ ì—…ë¬´ (ê¸°ì¡´ ê³ ê° ê´€ë¦¬, ìœ ì§€ë³´ìˆ˜)
5. **careon_application**: ì¼€ì–´ì˜¨ ì„œë¹„ìŠ¤ ì‹ ì²­ (ì¼€ì–´ì˜¨ ê´€ë ¨ ë°ì´í„°)

**ì‘ë‹µ í˜•ì‹** (ë‹¤ìŒ JSON í˜•ì‹ìœ¼ë¡œë§Œ ì‘ë‹µ):
```json
{{
  "inquiry_type": "ë¶„ë¥˜ëœ_íƒ€ì…",
  "confidence": 0.95,
  "reasoning": "ë¶„ë¥˜ ê·¼ê±° ì„¤ëª…",
  "suggested_mapping": {{
    "name": "ì´ë¦„_í•„ë“œëª…",
    "phone": "ì „í™”ë²ˆí˜¸_í•„ë“œëª…", 
    "address": "ì£¼ì†Œ_í•„ë“œëª…",
    "entry_date": "ì¸ì…ë‚ ì§œ_í•„ë“œëª…",
    "inquiry_source": "ë¬¸ì˜ì²˜_í•„ë“œëª…",
    "channel": "ì±„ë„_í•„ë“œëª…"
  }}
}}
```

ë°ì´í„° ë‚´ìš©ì„ ì‹ ì¤‘íˆ ë¶„ì„í•˜ì—¬ ê°€ì¥ ì ì ˆí•œ ë¶„ë¥˜ë¥¼ ì„ íƒí•˜ê³ , ê° í•„ë“œë¥¼ ì˜¬ë°”ë¥¸ ì»¬ëŸ¼ì— ë§¤í•‘í•´ì£¼ì„¸ìš”.
"""
        return prompt
    
    def _parse_classification_response(self, response_text: str) -> Dict[str, Any]:
        """Claude ì‘ë‹µ íŒŒì‹±"""
        try:
            # JSON ë¸”ë¡ ì¶”ì¶œ
            json_match = re.search(r'```json\s*(\{.*?\})\s*```', response_text, re.DOTALL)
            if json_match:
                json_text = json_match.group(1)
                return json.loads(json_text)
            
            # ì§ì ‘ JSON íŒŒì‹± ì‹œë„
            return json.loads(response_text.strip())
            
        except json.JSONDecodeError:
            logger.error(f"JSON íŒŒì‹± ì‹¤íŒ¨: {response_text}")
            return {
                "inquiry_type": "inquiry",
                "confidence": 0.5,
                "reasoning": "íŒŒì‹± ì‹¤íŒ¨ë¡œ ì¸í•œ ê¸°ë³¸ ë¶„ë¥˜",
                "suggested_mapping": {}
            }
    
    def _get_fallback_classification(self, sheet_name: str) -> Dict[str, Any]:
        """AI ë¶„ë¥˜ ì‹¤íŒ¨ ì‹œ ê¸°ë³¸ ë¶„ë¥˜"""
        # ì‹œíŠ¸ ì´ë¦„ ê¸°ë°˜ ê¸°ë³¸ ë¶„ë¥˜
        if 'careon' in sheet_name.lower() or 'ì¼€ì–´ì˜¨' in sheet_name:
            return {
                "inquiry_type": "careon_application",
                "confidence": 0.8,
                "reasoning": "ì‹œíŠ¸ ì´ë¦„ ê¸°ë°˜ ë¶„ë¥˜ (ì¼€ì–´ì˜¨)",
                "suggested_mapping": {}
            }
        else:
            return {
                "inquiry_type": "cctv_management",
                "confidence": 0.8,
                "reasoning": "ì‹œíŠ¸ ì´ë¦„ ê¸°ë°˜ ë¶„ë¥˜ (CCTV ê´€ë¦¬)",
                "suggested_mapping": {}
            }

class HeaderMapper:
    """ì‹œíŠ¸ë³„ í—¤ë” ë§¤í•‘ í´ë˜ìŠ¤"""
    
    # í‘œì¤€ í—¤ë” ë§¤í•‘
    STANDARD_MAPPING = {
        'NO': 'no',
        'no': 'no',
        'ë²ˆí˜¸': 'no',
        'ìˆœë²ˆ': 'no',
        
        'ì¸ì…ë‚ ì§œ': 'entry_date',
        'ë‚ ì§œ': 'entry_date',
        'ì ‘ìˆ˜ì¼': 'entry_date',
        'ë“±ë¡ì¼': 'entry_date',
        
        'ë¬¸ì˜': 'inquiry_source',
        'ë¬¸ì˜ì²˜': 'inquiry_source',
        'ì ‘ìˆ˜ì²˜': 'inquiry_source',
        
        'ì±„ë„': 'channel',
        'ìœ ì…ì±„ë„': 'channel',
        'ê²½ë¡œ': 'channel',
        
        'ì§€ì—­': 'region',
        'ì§€ì—­ëª…': 'region',
        'ì‹œë„': 'region',
        
        'í˜•íƒœ': 'form_type',
        'í¼íƒ€ì…': 'form_type',
        'ë¬¸ì˜í˜•íƒœ': 'form_type',
        
        'ìƒë‹´ë‚´ìš©(EA)': 'consultation_content',
        'ìƒë‹´ë‚´ìš©': 'consultation_content',
        'ë‚´ìš©': 'consultation_content',
        
        'ìƒë‹´ìš”ì²­': 'consultation_request',
        'ìš”ì²­ì‚¬í•­': 'consultation_request',
        
        'ì „í™”ë²ˆí˜¸': 'phone',
        'ì—°ë½ì²˜': 'phone',
        'íœ´ëŒ€í°': 'phone',
        'í•¸ë“œí°': 'phone',
        
        'ì´ë¦„': 'name',
        'ì„±ëª…': 'name',
        'ê³ ê°ëª…': 'name',
        
        '1ì°¨ì½œ': 'first_call',
        'í†µí™”ê²°ê³¼': 'first_call',
        'ì½œê²°ê³¼': 'first_call',
        
        'ë¹„ê³ ': 'notes',
        'ë©”ëª¨': 'notes',
        'ì°¸ê³ ì‚¬í•­': 'notes',
        
        # ì¼€ì–´ì˜¨ ì „ìš© í•„ë“œ
        'ì„¤ì¹˜ì§€ì—­': 'installation_location',
        'ì„¤ì¹˜ì¼ì •': 'installation_schedule',
        'ì‹ ì²­ì¼ì‹œ': 'application_datetime',
        'ì„œë¹„ìŠ¤': 'service_type'
    }
    
    @classmethod
    def map_headers(cls, headers: List[str], ai_mapping: Optional[Dict[str, str]] = None) -> Dict[str, str]:
        """í—¤ë”ë¥¼ í‘œì¤€ í•„ë“œëª…ìœ¼ë¡œ ë§¤í•‘"""
        mapping = {}
        ai_mapping = ai_mapping or {}  # Noneì¸ ê²½ìš° ë¹ˆ dictë¡œ ì´ˆê¸°í™”
        
        for header in headers:
            if header in cls.STANDARD_MAPPING:
                mapping[header] = cls.STANDARD_MAPPING[header]
            elif header in ai_mapping:
                mapping[header] = ai_mapping[header]
            else:
                # ê¸°ë³¸ ë§¤í•‘: ì†Œë¬¸ìë¡œ ë³€í™˜í•˜ê³  ê³µë°±ì„ ì–¸ë”ìŠ¤ì½”ì–´ë¡œ ë³€ê²½
                mapping[header] = header.lower().replace(' ', '_').replace('(', '').replace(')', '')
        
        return mapping

class CCTVSupabaseSync:
    """CCTV Google Sheetsì™€ Supabase ë™ê¸°í™” ì‹œìŠ¤í…œ"""
    
    def __init__(self):
        # í™˜ê²½ ë³€ìˆ˜ ê²€ì¦
        self.supabase_url = os.getenv('SUPABASE_URL')
        self.supabase_key = os.getenv('SUPABASE_SERVICE_ROLE_KEY')
        self.google_service_account = os.getenv('GOOGLE_SERVICE_ACCOUNT_FILE')
        self.google_sheets_url = os.getenv('GOOGLE_SHEETS_URL')
        self.anthropic_api_key = os.getenv('ANTHROPIC_API_KEY')
        
        # í•„ìˆ˜ í™˜ê²½ ë³€ìˆ˜ ê²€ì¦
        if not self.supabase_url or not self.supabase_key:
            raise ValueError("Supabase ì„¤ì •ì´ ëˆ„ë½ë˜ì—ˆìŠµë‹ˆë‹¤.")
        if not self.google_service_account or not self.google_sheets_url:
            raise ValueError("Google Sheets ì„¤ì •ì´ ëˆ„ë½ë˜ì—ˆìŠµë‹ˆë‹¤.")
        
        self.enable_ai_classification = os.getenv('ENABLE_AI_CLASSIFICATION', 'true').lower() == 'true'
        
        # í´ë¼ì´ì–¸íŠ¸ ì´ˆê¸°í™”
        self.supabase: Client = create_client(self.supabase_url, self.supabase_key)
        self.sheets_manager = GoogleSheetsManagerImproved(self.google_service_account)
        
        # AI ë¶„ë¥˜ê¸° ì´ˆê¸°í™”
        if self.enable_ai_classification and self.anthropic_api_key:
            self.ai_classifier = AIDataClassifier(self.anthropic_api_key)
        else:
            self.ai_classifier = None
            logger.warning("AI ë¶„ë¥˜ ê¸°ëŠ¥ì´ ë¹„í™œì„±í™”ë˜ì–´ ìˆìŠµë‹ˆë‹¤.")
    
    def sync_data(self):
        """Google Sheets ë°ì´í„°ë¥¼ Supabaseë¡œ ë™ê¸°í™”"""
        try:
            logger.info("ğŸ”„ ë°ì´í„° ë™ê¸°í™” ì‹œì‘...")
            
            # Google Sheets URL ê²€ì¦
            if not self.google_sheets_url:
                logger.error("âŒ Google Sheets URLì´ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
                return
            
            # ìŠ¤í”„ë ˆë“œì‹œíŠ¸ ID ì¶”ì¶œ
            spreadsheet_id = self.sheets_manager.extract_spreadsheet_id(self.google_sheets_url)
            
            # ì‹œíŠ¸ ë°ì´í„° ê°€ì ¸ì˜¤ê¸°
            sheet_data = self.sheets_manager.get_sheet_data_advanced(spreadsheet_id)
            
            if not sheet_data or not sheet_data.get('data'):
                logger.error("âŒ ì‹œíŠ¸ ë°ì´í„°ë¥¼ ê°€ì ¸ì˜¬ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
                return
            
            total_processed = 0
            
            for sheet_name, df in sheet_data['data'].items():
                if df.empty:
                    logger.info(f"âš ï¸ ë¹ˆ ì‹œíŠ¸ ê±´ë„ˆëœ€: {sheet_name}")
                    continue
                
                logger.info(f"ğŸ“Š ì²˜ë¦¬ ì¤‘ì¸ ì‹œíŠ¸: {sheet_name} ({len(df)} ë ˆì½”ë“œ)")
                
                # AI ë¶„ë¥˜ ìˆ˜í–‰
                classification_result = self._classify_sheet_data(sheet_name, df)
                
                # ë°ì´í„° ì²˜ë¦¬ ë° ì‚½ì…
                processed_count = self._process_and_insert_data(
                    sheet_name, df, classification_result
                )
                
                total_processed += processed_count
                
                # ë™ê¸°í™” ë¡œê·¸ ì—…ë°ì´íŠ¸
                self._update_sync_log(sheet_name, processed_count, "success")
            
            logger.info(f"âœ… ë™ê¸°í™” ì™„ë£Œ! ì´ {total_processed}ê°œ ë ˆì½”ë“œ ì²˜ë¦¬ë¨")
            
        except Exception as e:
            logger.error(f"âŒ ë™ê¸°í™” ì‹¤íŒ¨: {e}")
            self._update_sync_log("ì „ì²´", 0, "error", str(e))
    
    def _classify_sheet_data(self, sheet_name: str, df: pd.DataFrame) -> Dict[str, Any]:
        """ì‹œíŠ¸ ë°ì´í„°ë¥¼ AIë¡œ ë¶„ë¥˜"""
        if not self.ai_classifier:
            # AI ë¶„ë¥˜ê¸°ê°€ ì—†ì„ ë•ŒëŠ” ê¸°ë³¸ ë¶„ë¥˜ ì‚¬ìš©
            if 'careon' in sheet_name.lower() or 'ì¼€ì–´ì˜¨' in sheet_name:
                return {
                    "inquiry_type": "careon_application",
                    "confidence": 0.8,
                    "reasoning": "ì‹œíŠ¸ ì´ë¦„ ê¸°ë°˜ ë¶„ë¥˜ (ì¼€ì–´ì˜¨)",
                    "suggested_mapping": {}
                }
            else:
                return {
                    "inquiry_type": "cctv_management",
                    "confidence": 0.8,
                    "reasoning": "ì‹œíŠ¸ ì´ë¦„ ê¸°ë°˜ ë¶„ë¥˜ (CCTV ê´€ë¦¬)",
                    "suggested_mapping": {}
                }
        
        try:
            # ë°ì´í„° ìƒ˜í”Œ ì¤€ë¹„
            data_sample = []
            for _, row in df.head(5).iterrows():
                sample = {}
                for col in df.columns:
                    if pd.notna(row[col]):
                        str_value = str(row[col]).strip()
                        if len(str_value) > 0:
                            sample[col] = str_value
                data_sample.append(sample)
            
            logger.info(f"ğŸ¤– AI ë¶„ë¥˜ ì‹œì‘: {sheet_name}")
            
            # AI ë¶„ë¥˜ ì‹¤í–‰
            classification_result = self.ai_classifier.classify_data(sheet_name, data_sample)
            
            logger.info(f"ğŸ¯ AI ë¶„ë¥˜ ê²°ê³¼: {classification_result['inquiry_type']} "
                       f"(ì‹ ë¢°ë„: {classification_result['confidence']:.2f})")
            
            return classification_result
            
        except Exception as e:
            logger.error(f"AI ë¶„ë¥˜ ì‹¤íŒ¨: {e}")
            return self.ai_classifier._get_fallback_classification(sheet_name)
    
    def _process_and_insert_data(self, sheet_name: str, df: pd.DataFrame, 
                                classification_result: Dict[str, Any]) -> int:
        """ë°ì´í„° ì²˜ë¦¬ ë° ì‚½ì…"""
        try:
            # í—¤ë” ë§¤í•‘
            ai_mapping = classification_result.get('suggested_mapping', {})
            header_mapping = HeaderMapper.map_headers(df.columns.tolist(), ai_mapping)
            
            # ë°ì´í„° ë³€í™˜
            processed_records = []
            inquiry_type = classification_result['inquiry_type']
            
            for _, row in df.iterrows():
                record = self._create_standard_record(row, header_mapping, sheet_name, inquiry_type)
                if record:
                    processed_records.append(record)
            
            # ë°°ì¹˜ ì‚½ì…
            if processed_records:
                self.supabase.table('customer_inquiries').insert(processed_records).execute()
                logger.info(f"âœ… {len(processed_records)}ê°œ ë ˆì½”ë“œ ì‚½ì… ì™„ë£Œ: {sheet_name}")
                return len(processed_records)
            
            return 0
            
        except Exception as e:
            logger.error(f"ë°ì´í„° ì²˜ë¦¬ ì‹¤íŒ¨: {e}")
            return 0
    
    def _create_standard_record(self, row: pd.Series, header_mapping: Dict[str, str], 
                               sheet_name: str, inquiry_type: str) -> Optional[Dict]:
        """í‘œì¤€ ë ˆì½”ë“œ ìƒì„±"""
        try:
            # ê¸°ë³¸ ì •ë³´ ì¶”ì¶œ
            name = self._extract_field(row, header_mapping, ['name', 'customer_name'])
            phone = self._extract_field(row, header_mapping, ['phone', 'phone_number'])
            
            # ë¹ˆ ë ˆì½”ë“œ í•„í„°ë§ - ë¬¸ìì—´ ê¸¸ì´ë¡œ í™•ì¸
            if len(name) == 0 and len(phone) == 0:
                return None
            
            # í‘œì¤€ ë ˆì½”ë“œ ìƒì„±
            record = {
                'name': name or '',
                'phone': phone or '',
                'email': self._extract_field(row, header_mapping, ['email']),
                'address': self._extract_field(row, header_mapping, ['address']),
                'region': self._extract_field(row, header_mapping, ['region']),
                'inquiry_type': inquiry_type,
                'inquiry_source': self._extract_field(row, header_mapping, ['inquiry_source']),
                'channel': self._extract_field(row, header_mapping, ['channel']),
                'form_type': self._extract_field(row, header_mapping, ['form_type']),
                'consultation_content': self._extract_field(row, header_mapping, ['consultation_content']),
                'consultation_request': self._extract_field(row, header_mapping, ['consultation_request']),
                'first_call': self._extract_field(row, header_mapping, ['first_call']),
                'additional_notes': self._extract_field(row, header_mapping, ['notes']),
                'sheet_name': sheet_name,
                'status': 'pending',
                'created_at': datetime.now(timezone.utc).isoformat(),
                'updated_at': datetime.now(timezone.utc).isoformat()
            }
            
            # ì¼€ì–´ì˜¨ ì „ìš© í•„ë“œ ì¶”ê°€
            if inquiry_type == 'careon_application':
                record.update({
                    'installation_location': self._extract_field(row, header_mapping, ['installation_location']),
                    'installation_schedule': self._extract_field(row, header_mapping, ['installation_schedule']),
                    'application_datetime': self._extract_field(row, header_mapping, ['application_datetime']),
                    'service_type': self._extract_field(row, header_mapping, ['service_type'])
                })
            
            return record
            
        except Exception as e:
            logger.error(f"ë ˆì½”ë“œ ìƒì„± ì‹¤íŒ¨: {e}")
            return None
    
    def _extract_field(self, row: pd.Series, header_mapping: Dict[str, str], 
                      field_names: List[str]) -> str:
        """í•„ë“œ ê°’ ì¶”ì¶œ"""
        for field_name in field_names:
            # í—¤ë” ë§¤í•‘ì—ì„œ í•´ë‹¹ í•„ë“œë¥¼ ì°¾ìŒ
            for original_header, mapped_field in header_mapping.items():
                if mapped_field == field_name and original_header in row.index:
                    value = row[original_header]
                    if pd.notna(value):
                        str_value = str(value).strip()
                        if len(str_value) > 0:
                            return str_value
        return ''
    
    def _update_sync_log(self, sheet_name: str, records_count: int, status: str, 
                        error_message: Optional[str] = None):
        """ë™ê¸°í™” ë¡œê·¸ ì—…ë°ì´íŠ¸"""
        try:
            log_entry = {
                'sheet_name': sheet_name,
                'records_count': records_count,
                'status': status,
                'sync_timestamp': datetime.now(timezone.utc).isoformat(),
                'error_message': error_message
            }
            
            self.supabase.table('sync_log').insert(log_entry).execute()
            
        except Exception as e:
            logger.error(f"ë¡œê·¸ ì—…ë°ì´íŠ¸ ì‹¤íŒ¨: {e}")
    
    def start_scheduler(self):
        """ìŠ¤ì¼€ì¤„ëŸ¬ ì‹œì‘"""
        interval = int(os.getenv('SYNC_INTERVAL_MINUTES', '30'))
        
        schedule.every(interval).minutes.do(self.sync_data)
        
        logger.info(f"â° ìŠ¤ì¼€ì¤„ëŸ¬ ì‹œì‘: {interval}ë¶„ë§ˆë‹¤ ë™ê¸°í™”")
        
        while True:
            schedule.run_pending()
            time.sleep(1)

def main():
    """ë©”ì¸ ì‹¤í–‰ í•¨ìˆ˜"""
    sync_system = CCTVSupabaseSync()
    
    # ëª…ë ¹í–‰ ì¸ì ì²˜ë¦¬
    if len(sys.argv) > 1:
        if sys.argv[1] == 'once':
            # í•œ ë²ˆë§Œ ë™ê¸°í™”
            sync_system.sync_data()
        elif sys.argv[1] == 'schedule':
            # ìŠ¤ì¼€ì¤„ëŸ¬ ì‹œì‘
            sync_system.start_scheduler()
    else:
        # ê¸°ë³¸: í•œ ë²ˆë§Œ ë™ê¸°í™”
        sync_system.sync_data()

if __name__ == "__main__":
    main()